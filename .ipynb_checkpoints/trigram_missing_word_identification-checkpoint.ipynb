{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import nltk\n",
      "from pandas import DataFrame, Series"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "working_dir = r\"C:\\\\Users\\\\Schuster\\\\Documents\\\\1b_word\\\\\"\n",
      "test_sents = working_dir + r\"gen_test_data_start_25205893_len_1000.csv\"\n",
      "analysis = working_dir + r\"stats_1m_word_analysis.csv\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sent_df = DataFrame.from_csv(test_sents)\n",
      "analysis_df = DataFrame.from_csv(analysis)\n",
      "analysis_df = analysis_df[['Perc Total Unique', 'Perc Total 1+2', 'Perc Total 1']]\n",
      "empty_dict = Series({'Perc Total Unique': np.min(analysis_df['Perc Total Unique']) , 'Perc Total 1+2' : np.min(analysis_df['Perc Total Unique']), 'Perc Total 1' : np.min(analysis_df['Perc Total 1'])}, name='Empty')\n",
      "analysis_df = analysis_df.append(empty_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analysis_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Perc Total Unique</th>\n",
        "      <th>Perc Total 1+2</th>\n",
        "      <th>Perc Total 1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>DTNNPNNP</th>\n",
        "      <td> 0.005073</td>\n",
        "      <td> 0.380878</td>\n",
        "      <td> 0.053285</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>NNPNNPIN</th>\n",
        "      <td> 0.003155</td>\n",
        "      <td> 0.085136</td>\n",
        "      <td> 0.029088</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>NNPINNNP</th>\n",
        "      <td> 0.003448</td>\n",
        "      <td> 0.403265</td>\n",
        "      <td> 0.031791</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>INNNPNNP</th>\n",
        "      <td> 0.005587</td>\n",
        "      <td> 0.298048</td>\n",
        "      <td> 0.046347</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>NNPNNPCC</th>\n",
        "      <td> 0.001841</td>\n",
        "      <td> 0.049685</td>\n",
        "      <td> 0.016976</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 164,
       "text": [
        "          Perc Total Unique  Perc Total 1+2  Perc Total 1\n",
        "DTNNPNNP           0.005073        0.380878      0.053285\n",
        "NNPNNPIN           0.003155        0.085136      0.029088\n",
        "NNPINNNP           0.003448        0.403265      0.031791\n",
        "INNNPNNP           0.005587        0.298048      0.046347\n",
        "NNPNNPCC           0.001841        0.049685      0.016976"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sent_analysis(sent):\n",
      "    text = nltk.word_tokenize(sent)\n",
      "    pos_tags = nltk.pos_tag(text) ##(Word, POS)\n",
      "    words_with_trigrams = create_trigram_codes(pos_tags)\n",
      "    min_positions = grab_min_positions(words_with_trigrams)\n",
      "    return min_positions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_trigram_codes(pos_tag):\n",
      "    codes = []\n",
      "    for position in range(len(pos_tag) - 3):\n",
      "        phrase = pos_tag[position][0] + \" \" + pos_tag[position + 1][0] + \" \" + pos_tag[position + 2][0] \n",
      "        code = pos_tag[position][1] + pos_tag[position + 1][1] + pos_tag[position + 2][1]\n",
      "        codes.append([phrase, code])\n",
      "    phrase_info = []\n",
      "    n = 0\n",
      "    for phrase, code in codes:\n",
      "        try:\n",
      "            info = analysis_df.ix[code]\n",
      "        except KeyError:\n",
      "            info = analysis_df.ix['Empty']\n",
      "        print n, code, phrase\n",
      "        info = info.set_value('position', n)\n",
      "        n += 1\n",
      "        phrase_info.append(info)\n",
      "    return DataFrame(phrase_info)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grab_min_positions(trigrams):\n",
      "    min_positions = []\n",
      "    for c_name in trigrams.columns[:-1]:\n",
      "        next_position = trigrams[min(trigrams[c_name]) == trigrams[c_name]].position.values[0]\n",
      "        min_positions.append(next_position)\n",
      "    return min_positions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = test_sent_df.ix[3].values[0]\n",
      "print test_sent_df.ix[3]\n",
      "text = nltk.word_tokenize(sample)\n",
      "pos_tags = nltk.pos_tag(text)\n",
      "print pos_tags\n",
      "codes = create_trigram_codes(pos_tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "alt_sent           The added space should let you clean out your ...\n",
        "missing_word_at                                                   10\n",
        "Name: 3, dtype: object\n",
        "[('The', 'DT'), ('added', 'VBN'), ('space', 'NN'), ('should', 'MD'), ('let', 'VB'), ('you', 'PRP'), ('clean', 'JJ'), ('out', 'RP'), ('your', 'PRP$'), ('vanity', 'NN'), (',', ','), ('where', 'WRB'), ('you', 'PRP'), ('can', 'MD'), ('hide', 'VB'), ('a', 'DT'), ('laundry', 'NN'), ('basket', 'NN'), ('like', 'IN'), ('Umbra', 'NNP'), (\"'s\", 'POS'), ('Crunch', 'NNP'), ('can', 'MD'), (',', ','), ('above', 'VB'), ('(', ':'), ('$', '$'), ('21', 'CD'), ('to', 'TO'), ('$', '$'), ('26.50', 'CD'), (',', ','), ('from', 'IN'), ('800-387-5122', 'CD'), ('or', 'CC'), ('umbra.com', 'JJ'), (')', 'NN'), (',', ','), ('which', 'WDT'), ('can', 'MD'), ('be', 'VB'), ('adjusted', 'VBN'), ('in', 'IN'), ('height', 'NN'), ('.', '.')]\n",
        "0 DTVBNNN The added space\n",
        "1"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "set_value() takes exactly 4 arguments (3 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-204-032d2b638198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpos_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_trigram_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-201-c0f2d0bcca2a>\u001b[0m in \u001b[0;36mcreate_trigram_codes\u001b[1;34m(pos_tag)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalysis_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Empty'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'position'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mphrase_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: set_value() takes exactly 4 arguments (3 given)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " VBNNNMD added space should\n",
        "2 NNMDVB space should let\n",
        "3 MDVBPRP should let you\n",
        "4 VBPRPJJ let you clean\n"
       ]
      }
     ],
     "prompt_number": 204
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(10):\n",
      "    sentence, missing_value = test_sent_df.ix[i]\n",
      "    best_guess_missing = sent_analysis(sentence)\n",
      "    print \"Missing Value: \" + str(missing_value)\n",
      "    print \"Best Guess: \" + str(best_guess_missing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "Missing Value: 2\n",
        "Best Guess: [0.0, 2.0, 0.0]\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "Missing Value: 3\n",
        "Best Guess: [3.0, 3.0, 4.0]\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7\n",
        "Missing Value: 9\n",
        "Best Guess: [4.0, 6.0, 4.0]\n",
        "0"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "set_value() takes exactly 4 arguments (3 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-190-93f15f1fb7b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_sent_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mbest_guess_missing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Missing Value: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Best Guess: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_guess_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-165-573603136f90>\u001b[0m in \u001b[0;36msent_analysis\u001b[1;34m(sent)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpos_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m##(Word, POS)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mwords_with_trigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_trigram_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmin_positions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrab_min_positions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_with_trigrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmin_positions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-188-255a07c50ca3>\u001b[0m in \u001b[0;36mcreate_trigram_codes\u001b[1;34m(pos_tag)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalysis_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Empty'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'position'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mphrase_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: set_value() takes exactly 4 arguments (3 given)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}